{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bjornaer/bjornaer/blob/main/finetune_stable_dif.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUUnmQGHm3a4",
        "outputId": "22843a11-6b13-4f03-f6c3-e81229df9ef2"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Step 0** - Choose some 20 pics of you\n",
        "where your face appears, some 3 or 4 full body, some 4 or 5 half-body and the rest of the face. Edit them, resize or cut, but they need to be 512x512 pixels -- if you deform the image the AI will learn to draw you deformed too."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCgtpGr6ZOyG"
      },
      "source": [
        "### **Step 1** - Connect to Google Drive. **Need 4GB space available.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4Bae3VP6UsE",
        "outputId": "3dc5a1ce-e172-4450-f81f-5deeaba4b9b3"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbKbx185zqlz"
      },
      "source": [
        "### **Step 2** - Install dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyvcqeiL65Tj"
      },
      "outputs": [],
      "source": [
        "#@markdown # Dependencies\n",
        "%%capture\n",
        "%cd /content/\n",
        "!git clone https://github.com/TheLastBen/diffusers\n",
        "!pip install -q git+https://github.com/TheLastBen/diffusers\n",
        "!pip install -q accelerate==0.12.0\n",
        "!pip install -q OmegaConf\n",
        "!pip install -q torchsde\n",
        "!pip install transformers\n",
        "!pip install bitsandbytes\n",
        "!pip install fastapi\n",
        "!wget https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/Deps\n",
        "!mv Deps Deps.7z\n",
        "!7z x Deps.7z\n",
        "!cp -r /content/usr/local/lib/python3.7/dist-packages /usr/local/lib/python3.7/\n",
        "!rm Deps.7z\n",
        "!rm -r /content/usr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pld5ps87a1q",
        "outputId": "307ca3c2-d699-462a-99f5-84c0ebbabdc2"
      },
      "outputs": [],
      "source": [
        "#@markdown # xformers\n",
        "\n",
        "from subprocess import getoutput\n",
        "from IPython.display import HTML\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "\n",
        "s = getoutput('nvidia-smi')\n",
        "if 'T4' in s:\n",
        "  gpu = 'T4'\n",
        "elif 'P100' in s:\n",
        "  gpu = 'P100'\n",
        "elif 'V100' in s:\n",
        "  gpu = 'V100'\n",
        "elif 'A100' in s:\n",
        "  gpu = 'A100'\n",
        "\n",
        "while True:\n",
        "    try: \n",
        "        gpu=='T4'or gpu=='P100'or gpu=='V100'or gpu=='A100'\n",
        "        break\n",
        "    except:\n",
        "        pass\n",
        "    print('\u001b[1;31mit seems that your GPU is not supported at the moment')\n",
        "    time.sleep(5)\n",
        "\n",
        "if (gpu=='T4'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/T4/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "  \n",
        "elif (gpu=='P100'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/P100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "\n",
        "elif (gpu=='V100'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/V100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "\n",
        "elif (gpu=='A100'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/A100/xformers-0.0.13.dev0-py3-none-any.whl  \n",
        "\n",
        "clear_output()\n",
        "print('\u001b[1;32mDONE !')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Step 3** \n",
        "Go to [huggingface](https://huggingface.co/) and create an account, [accept the terms of use of the ML model](https://huggingface.co/runwayml/stable-diffusion-v1-5) and [create an Access token with write access](https://huggingface.co/settings/tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnBAZ4eje2Sl"
      },
      "source": [
        "### **Step 4** - Download Stable Diffusion model in `.ckpt` format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3KHGKqyeJp9",
        "outputId": "abbc4891-1548-477f-e093-567514dbea06"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "from IPython.utils import capture\n",
        "\n",
        "with capture.capture_output() as cap: \n",
        "  %cd /content/\n",
        "#@markdown ---\n",
        "Huggingface_Token = \"<API TOKEN>\" #@param {type:\"string\"}\n",
        "token=Huggingface_Token\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "CKPT_Path = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Or\n",
        "\n",
        "CKPT_gdrive_Link = \"\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "if CKPT_Path !=\"\":\n",
        "  if os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "    !rm -r /content/stable-diffusion-v1-5\n",
        "  if os.path.exists(str(CKPT_Path)):\n",
        "    !mkdir /content/stable-diffusion-v1-5\n",
        "    with capture.capture_output() as cap: \n",
        "      !wget https://raw.githubusercontent.com/huggingface/diffusers/main/scripts/convert_original_stable_diffusion_to_diffusers.py\n",
        "    !python /content/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path \"$CKPT_Path\" --dump_path /content/stable-diffusion-v1-5\n",
        "    if os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "      !rm /content/convert_original_stable_diffusion_to_diffusers.py\n",
        "      !rm /content/v1-inference.yaml\n",
        "      clear_output()\n",
        "      print('\u001b[1;32mDONE !')\n",
        "    else:\n",
        "      !rm /content/convert_original_stable_diffusion_to_diffusers.py\n",
        "      !rm /content/v1-inference.yaml\n",
        "      !rm -r /content/stable-diffusion-v1-5\n",
        "      while not os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "        print('\u001b[1;31mConversion error, check your CKPT and try again')\n",
        "        time.sleep(5)\n",
        "  else:\n",
        "    while not os.path.exists(str(CKPT_Path)):\n",
        "       print('\u001b[1;31mWrong path, use the colab file explorer to copy the path')\n",
        "       time.sleep(5)\n",
        "\n",
        "\n",
        "elif CKPT_gdrive_Link !=\"\":   \n",
        "    if os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "      !rm -r /content/stable-diffusion-v1-5     \n",
        "    !gdown --fuzzy $CKPT_gdrive_Link -O model.ckpt    \n",
        "    if os.path.exists('/content/model.ckpt'):\n",
        "      if os.path.getsize(\"/content/model.ckpt\") > 1810671599:\n",
        "        !mkdir /content/stable-diffusion-v1-5\n",
        "        with capture.capture_output() as cap: \n",
        "          !wget https://raw.githubusercontent.com/huggingface/diffusers/main/scripts/convert_original_stable_diffusion_to_diffusers.py\n",
        "        !python /content/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path /content/model.ckpt --dump_path /content/stable-diffusion-v1-5\n",
        "        if os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "          clear_output()\n",
        "          print('\u001b[1;32mDONE !')\n",
        "          !rm /content/convert_original_stable_diffusion_to_diffusers.py\n",
        "          !rm /content/v1-inference.yaml\n",
        "          !rm /content/model.ckpt\n",
        "        else:\n",
        "          if os.path.exists('/content/v1-inference.yaml'):\n",
        "            !rm /content/v1-inference.yaml\n",
        "          !rm /content/convert_original_stable_diffusion_to_diffusers.py\n",
        "          !rm -r /content/stable-diffusion-v1-5\n",
        "          !rm /content/model.ckpt\n",
        "          while not os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "            print('\u001b[1;31mConversion error, check your CKPT and try again')\n",
        "            time.sleep(5)\n",
        "      else:\n",
        "        while os.path.getsize('/content/model.ckpt') < 1810671599:\n",
        "           print('\u001b[1;31mWrong link, check that the link is valid')\n",
        "           time.sleep(5)\n",
        "\n",
        "\n",
        "elif token ==\"\":\n",
        "  if os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "    !rm -r /content/stable-diffusion-v1-5\n",
        "  clear_output()\n",
        "  token=input(\"Insert your huggingface token :\")\n",
        "  %cd /content/\n",
        "  clear_output()\n",
        "  !mkdir /content/stable-diffusion-v1-5\n",
        "  %cd /content/stable-diffusion-v1-5\n",
        "  !git init\n",
        "  !git lfs install --system --skip-repo\n",
        "  !git remote add -f origin  \"https://USER:{token}@huggingface.co/runwayml/stable-diffusion-v1-5\"\n",
        "  !git config core.sparsecheckout true\n",
        "  !echo -e \"feature_extractor\\nsafety_checker\\nscheduler\\ntext_encoder\\ntokenizer\\nunet\\nmodel_index.json\" > .git/info/sparse-checkout\n",
        "  !git pull origin main\n",
        "  if os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "    !git clone \"https://USER:{token}@huggingface.co/stabilityai/sd-vae-ft-mse\"\n",
        "    !mv /content/stable-diffusion-v1-5/sd-vae-ft-mse /content/stable-diffusion-v1-5/vae\n",
        "    !rm -r /content/stable-diffusion-v1-5/.git\n",
        "    %cd /content/    \n",
        "    clear_output()\n",
        "    print('\u001b[1;32mDONE !')\n",
        "  else:\n",
        "    while not os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "         print('\u001b[1;31mMake sure you accepted the terms in https://huggingface.co/runwayml/stable-diffusion-v1-5')\n",
        "         time.sleep(5)\n",
        "         \n",
        "elif token !=\"\":\n",
        "  if os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "    !rm -r /content/stable-diffusion-v1-5   \n",
        "  clear_output()\n",
        "  %cd /content/\n",
        "  clear_output()\n",
        "  !mkdir /content/stable-diffusion-v1-5\n",
        "  %cd /content/stable-diffusion-v1-5\n",
        "  !git init\n",
        "  !git lfs install --system --skip-repo\n",
        "  !git remote add -f origin  \"https://USER:{token}@huggingface.co/runwayml/stable-diffusion-v1-5\"\n",
        "  !git config core.sparsecheckout true\n",
        "  !echo -e \"feature_extractor\\nsafety_checker\\nscheduler\\ntext_encoder\\ntokenizer\\nunet\\nmodel_index.json\" > .git/info/sparse-checkout\n",
        "  !git pull origin main\n",
        "  if os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "    !git clone \"https://USER:{token}@huggingface.co/stabilityai/sd-vae-ft-mse\"\n",
        "    !mv /content/stable-diffusion-v1-5/sd-vae-ft-mse /content/stable-diffusion-v1-5/vae\n",
        "    !rm -r /content/stable-diffusion-v1-5/.git\n",
        "    %cd /content/    \n",
        "    clear_output()\n",
        "    print('\u001b[1;32mDONE !')\n",
        "  else:\n",
        "    while not os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "         print('\u001b[1;31mMake sure you accepted the terms in https://huggingface.co/runwayml/stable-diffusion-v1-5')\n",
        "         time.sleep(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wsp71Ctje5qg"
      },
      "source": [
        "### **Step 5** - Config Dreambooth.\n",
        "Here you need to choose an instance name -- a keyword that will mean *you* for the AI. This should be something mostly unique (dont choose `napoleon` y'know?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "(When you run the code below you will get prompted to upload an image at the end of the cell, upload 1 image and check the folders to the left.\n",
        "\n",
        "If you find a folder called `content/data/<you>` right-click it and then click `upload` and then you can bulk-upload the rest of your pics there.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "1pH1oP-7yBZm",
        "outputId": "ca77551d-163b-41ba-e9e9-82e9c60883a2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output\n",
        "from IPython.utils import capture\n",
        "#@markdown ---\n",
        "Training_Subject = \"Character\" #@param [\"Character\", \"Object\", \"Style\", \"Artist\", \"Movie\", \"TV Show\"] \n",
        "\n",
        "With_Prior_Preservation = \"Yes\" #@param [\"Yes\", \"No\"] \n",
        "#@markdown - With the prior reservation method, the results are better, you will either have to upload around 200 pictures of the class you're training (dog, person, car, house ...) or let Dreambooth generate them.\n",
        "\n",
        "MODEL_NAME=\"/content/stable-diffusion-v1-5\"\n",
        "\n",
        "Captionned_instance_images = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown - Use the keywords included in each instance images as unique instance prompt, this allows to train on multiple subjects at the same time, example : \n",
        "#@markdown - An instance image named fat_dog_doginstancename_in_a_pool.jpg\n",
        "#@markdown - another instance image named a_cat_catinstancename_in_the_woods.png\n",
        "#@markdown - the unique training instance prompts would be : fat dog doginstancename in a pool, a cat doginstancename in the woods\n",
        "#@markdown - at inference you can generate the dog by simply using doginstancename (a random unique identifier) or the cat by catinstancename\n",
        "\n",
        "#@markdown - Also you can enhance the training of a simple subject by simply describing the image using keywords like : smiling, outdoor, sad, lether jacket ...etc\n",
        "\n",
        "#@markdown - If you enable this feature, and want to train on multiple subjects, use the AUTOMATIC1111 colab to generate good quality 512x512 100-200 Class images for each subject (dog and a cat and a cow), then put them all in the same folder and entrer the folder's path in the cell below.\n",
        "\n",
        "#@markdown - If you enable this feature, you must add an instance name and a subject type (dog, man, car) to all the images, separate keywords by an underscore (_).\n",
        "\n",
        "\n",
        "\n",
        "SUBJECT_TYPE = \"person\" #@param{type: 'string'}\n",
        "while SUBJECT_TYPE==\"\":\n",
        "   SUBJECT_TYPE=input('Input the subject type:')\n",
        "\n",
        "#@markdown - If you're training on a character or an object, the subject type would be : Man, Woman, Shirt, Car, Dog, Baby ...etc\n",
        "#@markdown - If you're training on a Style, the subject type would be : impressionist, brutalist, abstract, use \"beautiful\" for a general style...etc\n",
        "#@markdown - If you're training on a Movie/Show, the subject type would be : Action, Drama, Science-fiction, Comedy ...etc\n",
        "#@markdown - If you're training on an Artist, the subject type would be : Painting, sketch, drawing, photography, art ...etc\n",
        "\n",
        "\n",
        "INSTANCE_NAME= \"<CHOOSE A KEYWORD FOR YOU>\" #@param{type: 'string'}\n",
        "while INSTANCE_NAME==\"\":\n",
        "   INSTANCE_NAME=input('Input the instance name (identifier) :')\n",
        "\n",
        "#@markdown - The instance is an identifier, choose a unique identifier unknown by stable diffusion. \n",
        "\n",
        "INSTANCE_DIR_OPTIONAL=\"\" #@param{type: 'string'}\n",
        "INSTANCE_DIR=INSTANCE_DIR_OPTIONAL\n",
        "while INSTANCE_DIR_OPTIONAL!=\"\" and not os.path.exists(str(INSTANCE_DIR)):\n",
        "    INSTANCE_DIR=input('\u001b[1;31mThe instance folder specified does not exist, use the colab file explorer to copy the path :')\n",
        "\n",
        "#@markdown - If the number of instance pictures is large, it is preferable to specify directly the folder instead of uploading, leave EMPTY to upload.\n",
        "\n",
        "CLASS_DIR=\"/content/data/\"+ SUBJECT_TYPE\n",
        "Number_of_subject_images=500#@param{type: 'number'}\n",
        "while Number_of_subject_images==None:\n",
        "     Number_of_subject_images=input('Input the number of subject images :')\n",
        "SUBJECT_IMAGES=Number_of_subject_images\n",
        "\n",
        "Save_class_images_to_gdrive = False #@param {type:\"boolean\"}\n",
        "#@markdown - Save time in case you're training multiple instances of the same class\n",
        "\n",
        "if Training_Subject==\"Character\" or Training_Subject==\"Object\":\n",
        "  PT=\"photo of \"+INSTANCE_NAME+\" \"+SUBJECT_TYPE\n",
        "  CPT=\"a photo of a \"+SUBJECT_TYPE+\", ultra detailed\"\n",
        "  if Captionned_instance_images:\n",
        "    PT=\"photo of\"\n",
        "elif Training_Subject==\"Style\":\n",
        "  With_Prior_Preservation = \"No\"\n",
        "  PT=\"in the \"+SUBJECT_TYPE+\" style of \"+INSTANCE_NAME\n",
        "  if Captionned_instance_images:\n",
        "    PT=\"in the style of\"  \n",
        "elif Training_Subject==\"Artist\":\n",
        "  With_Prior_Preservation = \"No\"\n",
        "  PT=SUBJECT_TYPE+\" By \"+INSTANCE_NAME\n",
        "  if Captionned_instance_images:\n",
        "    PT=\"by the artist\"  \n",
        "elif Training_Subject==\"Movie\":\n",
        "  PT=\"from the \"+SUBJECT_TYPE+\" movie \"+ INSTANCE_NAME\n",
        "  CPT=\"still frame from \"+SUBJECT_TYPE+\" movie, ultra detailed, 4k uhd\"\n",
        "  if Captionned_instance_images:\n",
        "    PT=\"from the movie\"  \n",
        "elif Training_Subject==\"TV Show\":\n",
        "  CPT=\"still frame from \"+SUBJECT_TYPE+\" tv show, ultra detailed, 4k uhd\"\n",
        "  PT=\"from the \"+SUBJECT_TYPE+\" tv show \"+ INSTANCE_NAME\n",
        "  if Captionned_instance_images:\n",
        "    PT=\"from the tv show\"    \n",
        "  \n",
        "OUTPUT_DIR=\"/content/models/\"+ INSTANCE_NAME\n",
        "\n",
        "if INSTANCE_DIR_OPTIONAL==\"\":\n",
        "  INSTANCE_DIR=\"/content/data/\"+INSTANCE_NAME\n",
        "  !mkdir -p \"$INSTANCE_DIR\"\n",
        "  uploaded = files.upload()\n",
        "  for filename in uploaded.keys():\n",
        "    shutil.move(filename, INSTANCE_DIR)\n",
        "    clear_output()\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "   %cd \"$INSTANCE_DIR\"\n",
        "   !find . -name \"* *\" -type f | rename 's/ /_/g'\n",
        "   %cd /content\n",
        "print('\u001b[1;32mOK')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYmyuQctfATh"
      },
      "source": [
        "### **Step 6** - (Optional, but good) Download regularization imgs\n",
        "match the dataset to your type of subject (person for example..)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ze4P8wWPjy7F",
        "outputId": "bc97bff1-5a67-4f23-ebe4-cd0ba30eb127"
      },
      "outputs": [],
      "source": [
        "#@markdown Weâ€™ve created the following image sets\n",
        "#@markdown - `man_euler` - provided by Niko Pueringer (Corridor Digital) - euler @ 40 steps, CFG 7.5\n",
        "#@markdown - `man_unsplash` - pictures from various photographers\n",
        "#@markdown - `person_ddim`\n",
        "#@markdown - `woman_ddim` - provided by David Bielejeski - ddim @ 50 steps, CFG 10.0 <br />\n",
        "#@markdown - `blonde_woman` - provided by David Bielejeski - ddim @ 50 steps, CFG 10.0 <br />\n",
        "\n",
        "dataset=\"person_ddim\" #@param [\"man_euler\", \"man_unsplash\", \"person_ddim\", \"woman_ddim\", \"blonde_woman\"]\n",
        "!git clone https://github.com/djbielejeski/Stable-Diffusion-Regularization-Images-{dataset}.git\n",
        "\n",
        "!mkdir -p regularization_images/{dataset}\n",
        "!mv -v Stable-Diffusion-Regularization-Images-{dataset}/{dataset}/*.* regularization_images/{dataset}\n",
        "CLASS_DIR=\"/content/regularization_images/\" + dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmIz45s0gH5c"
      },
      "source": [
        "### **Step 7** - Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-9QbkfAVYYU",
        "outputId": "0b496645-f475-4b92-eb5e-dbc1fc60bc7a"
      },
      "outputs": [],
      "source": [
        "#@markdown ---\n",
        "import os\n",
        "from subprocess import getoutput\n",
        "from IPython.display import HTML\n",
        "\n",
        "fp16 = True #@param {type:\"boolean\"}\n",
        "if fp16:\n",
        "  prec=\"fp16\"\n",
        "else:\n",
        "  prec=\"no\"\n",
        "\n",
        "#@markdown  - fp16 or half precision meaning slightly lower quality but double the speed.\n",
        "s = getoutput('nvidia-smi')\n",
        "if 'A100' in s:\n",
        "  precision=\"no\"\n",
        "else:\n",
        "  precision=prec\n",
        "\n",
        "Training_Steps=\"1600\" #@param{type: 'string'}\n",
        "#@markdown - Keep it around 1600 to avoid overtraining.\n",
        "\n",
        "Seed=75576 #@param{type: 'number'}\n",
        "\n",
        "#@markdown ---------------------------\n",
        "Save_Checkpoint_Every_n_Steps = False #@param {type:\"boolean\"}\n",
        "Save_Checkpoint_Every=500 #@param{type: 'number'}\n",
        "if Save_Checkpoint_Every==None:\n",
        "  Save_Checkpoint_Every=1\n",
        "#@markdown - Minimum 200 steps between each save.\n",
        "stp=0\n",
        "Start_saving_from_the_step=500 #@param{type: 'number'}\n",
        "if Start_saving_from_the_step==None:\n",
        "  Start_saving_from_the_step=0\n",
        "if (Start_saving_from_the_step < 200):\n",
        "  Start_saving_from_the_step=Save_Checkpoint_Every\n",
        "stpsv=Start_saving_from_the_step\n",
        "if Save_Checkpoint_Every_n_Steps:\n",
        "  stp=Save_Checkpoint_Every\n",
        "#@markdown - Start saving intermediary checkpoints from this step.\n",
        "\n",
        "Caption=''\n",
        "if Captionned_instance_images:\n",
        "  Caption='--image_captions_filename'\n",
        "\n",
        "if With_Prior_Preservation=='No':\n",
        "  !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "    $Caption \\\n",
        "    --save_steps=500 \\\n",
        "    --train_text_encoder \\\n",
        "    --pretrained_model_name_or_path=\"$MODEL_NAME\" \\\n",
        "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "    --output_dir=\"$OUTPUT_DIR\" \\\n",
        "    --instance_prompt=\"$PT\" \\\n",
        "    --seed=$Seed \\\n",
        "    --resolution=512 \\\n",
        "    --mixed_precision=$precision \\\n",
        "    --train_batch_size=1 \\\n",
        "    --gradient_accumulation_steps=1 \\\n",
        "    --use_8bit_adam \\\n",
        "    --learning_rate=1e-6 \\\n",
        "    --lr_scheduler=\"constant\" \\\n",
        "    --center_crop \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --max_train_steps=$Training_Steps \n",
        "\n",
        "else:\n",
        "\n",
        "  !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "    $Caption \\\n",
        "    --save_steps=500 \\\n",
        "    --train_text_encoder \\\n",
        "    --pretrained_model_name_or_path=\"$MODEL_NAME\" \\\n",
        "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "    --class_data_dir=\"$CLASS_DIR\" \\\n",
        "    --output_dir=\"$OUTPUT_DIR\" \\\n",
        "    --with_prior_preservation --prior_loss_weight=1.0 \\\n",
        "    --instance_prompt=\"$PT\"\\\n",
        "    --class_prompt=\"$CPT\" \\\n",
        "    --seed=$Seed \\\n",
        "    --resolution=512 \\\n",
        "    --mixed_precision=$precision \\\n",
        "    --train_batch_size=1 \\\n",
        "    --gradient_accumulation_steps=1 --gradient_checkpointing \\\n",
        "    --use_8bit_adam \\\n",
        "    --learning_rate=1e-6 \\\n",
        "    --lr_scheduler=\"constant\" \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --center_crop \\\n",
        "    --max_train_steps=$Training_Steps \\\n",
        "    --num_class_images=$SUBJECT_IMAGES\n",
        "\n",
        "if Save_class_images_to_gdrive:\n",
        "  if os.path.exists(str(CLASS_DIR)):\n",
        "    if not os.path.exists('/content/gdrive/MyDrive/Class_images'):\n",
        "      !mkdir /content/gdrive/MyDrive/Class_images\n",
        "    Class_gdir= '/content/gdrive/MyDrive/Class_images/'+SUBJECT_TYPE\n",
        "    if not os.path.exists(str(Class_gdir)):\n",
        "      !cp -r \"$CLASS_DIR\" /content/gdrive/MyDrive/Class_images\n",
        "\n",
        "if os.path.exists('/content/models/'+INSTANCE_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
        "  print(\"Almost done ...\")\n",
        "  %cd /content    \n",
        "  !wget -O convertosd.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertosd.py\n",
        "  clear_output()\n",
        "  if precision==\"no\":\n",
        "    !sed -i '226s@.*@@' /content/convertosd.py\n",
        "  !sed -i '201s@.*@    model_path = \"{OUTPUT_DIR}\"@' /content/convertosd.py\n",
        "  !sed -i '202s@.*@    checkpoint_path= \"/content/gdrive/MyDrive/{INSTANCE_NAME}.ckpt\"@' /content/convertosd.py\n",
        "  !python /content/convertosd.py\n",
        "  clear_output()\n",
        "  if os.path.exists('/content/gdrive/MyDrive/'+INSTANCE_NAME+'.ckpt'):\n",
        "    print(\"\u001b[1;32mDONE, the CKPT model is in your Gdrive\")\n",
        "  else:\n",
        "    print(\"\u001b[1;31mSomething went wrong\")\n",
        "else:\n",
        "  print(\"\u001b[1;31mSomething went wrong\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qbclw_Gmg3DC"
      },
      "source": [
        "### **Step 8** - Try it out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "iAZGngFcI8hq",
        "outputId": "dac0a609-27ef-42af-ca1f-8445c738a50b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from IPython.display import clear_output\n",
        "from subprocess import getoutput\n",
        "from IPython.utils import capture\n",
        "import time\n",
        "\n",
        "Update_repo = False #@param {type:\"boolean\"}\n",
        "\n",
        "INSTANCE__NAME=\"\" #@param{type: 'string'}\n",
        "\n",
        "#@markdown - Leave empty if you want to use the current trained model\n",
        "\n",
        "if INSTANCE__NAME!=\"\":\n",
        "  INSTANCE_NAME=INSTANCE__NAME\n",
        "\n",
        "Use_Custom_Path = False #@param {type:\"boolean\"}\n",
        "\n",
        "try:\n",
        "  INSTANCE_NAME\n",
        "  if Use_Custom_Path:\n",
        "    del INSTANCE_NAME\n",
        "except:\n",
        "  pass\n",
        "#@markdown - if checked, an input box will ask the full path to a desired model\n",
        "\n",
        "try:\n",
        "  INSTANCE_NAME\n",
        "  path_to_trained_model='/content/gdrive/MyDrive/'+INSTANCE_NAME+'.ckpt'\n",
        "except:\n",
        "  print('\u001b[1;31mIt seems that you did not perform training during this session \u001b[1;32mor you chose to use a custom path,\\nprovide the full path to the model (including the name of the model):\\n')\n",
        "  path_to_trained_model=input()\n",
        "     \n",
        "while not os.path.exists(path_to_trained_model):\n",
        "   print(\"\u001b[1;31mThe model doesn't exist on you Gdrive, use the file explorer to get the path : \")\n",
        "   path_to_trained_model=input()\n",
        "\n",
        "         \n",
        "with capture.capture_output() as cap:\n",
        "    %cd /content/gdrive/MyDrive/\n",
        "    %mkdir sd\n",
        "    %cd sd\n",
        "    !git clone https://github.com/CompVis/stable-diffusion\n",
        "    !git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui\n",
        "    %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/\n",
        "    !mkdir -p cache/{huggingface,torch}\n",
        "    %cd /content/\n",
        "    !ln -s /content/gdrive/MyDrive/sd/stable-diffusion-webui/cache/huggingface ../root/.cache/\n",
        "    !ln -s /content/gdrive/MyDrive/sd/stable-diffusion-webui/cache/torch ../root/.cache/\n",
        "\n",
        "if Update_repo:\n",
        "  !rm /content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.sh  \n",
        "  !rm /content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/paths.py\n",
        "  !rm /content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.py \n",
        "  !rm /content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/ui.py\n",
        "  !rm /content/gdrive/MyDrive/sd/stable-diffusion-webui/style.css\n",
        "  %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/\n",
        "  clear_output()\n",
        "  print('\u001b[1;32m')\n",
        "  !git pull\n",
        "\n",
        "\n",
        "with capture.capture_output() as cap:  \n",
        "  if not os.path.exists('/content/gdrive/MyDrive/sd/stable-diffusion/src/k-diffusion/k_diffusion'):\n",
        "    !mkdir /content/gdrive/MyDrive/sd/stable-diffusion/src\n",
        "    %cd /content/gdrive/MyDrive/sd/stable-diffusion/src\n",
        "    !git clone https://github.com/CompVis/taming-transformers\n",
        "    !git clone https://github.com/openai/CLIP\n",
        "    !mv /content/gdrive/MyDrive/sd/stable-diffusion/src/CLIP /content/gdrive/MyDrive/sd/stable-diffusion/src/clip\n",
        "    !git clone https://github.com/TencentARC/GFPGAN\n",
        "    !mv  /content/gdrive/MyDrive/sd/stable-diffusion/src/GFPGAN/gfpgan /content/gdrive/MyDrive/sd/stable-diffusion-webui\n",
        "    !git clone https://github.com/salesforce/BLIP\n",
        "    !mv  /content/gdrive/MyDrive/sd/stable-diffusion/src/BLIP /content/gdrive/MyDrive/sd/stable-diffusion/src/blip\n",
        "    !git clone https://github.com/sczhou/CodeFormer\n",
        "    !mv  /content/gdrive/MyDrive/sd/stable-diffusion/src/CodeFormer /content/gdrive/MyDrive/sd/stable-diffusion/src/codeformer\n",
        "    !git clone https://github.com/xinntao/Real-ESRGAN\n",
        "    !mv  /content/gdrive/MyDrive/sd/stable-diffusion/src/Real-ESRGAN/ /content/gdrive/MyDrive/sd/stable-diffusion/src/realesrgan\n",
        "    !git clone https://github.com/crowsonkb/k-diffusion.git\n",
        "    !cp -r /content/gdrive/MyDrive/sd/stable-diffusion/src/k-diffusion/k_diffusion /content/gdrive/MyDrive/sd/stable-diffusion-webui\n",
        "    !git clone https://github.com/Hafiidz/latent-diffusion\n",
        "    !cp -r  /content/gdrive/MyDrive/sd/stable-diffusion/ldm /content/gdrive/MyDrive/sd/stable-diffusion-webui/\n",
        "\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  if not os.path.exists('/usr/local/lib/python3.7/dist-packages/gradio-3.4b3.dist-info'):\n",
        "    %cd /content/\n",
        "    !wget https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dependencies/Dependencies_AUT.1\n",
        "    !wget https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dependencies/Dependencies_AUT.2\n",
        "    %mv Dependencies_AUT.1 Dependencies_AUT.7z.001\n",
        "    %mv Dependencies_AUT.2 Dependencies_AUT.7z.002\n",
        "    !7z x Dependencies_AUT.7z.001\n",
        "    time.sleep(2)\n",
        "    !rm -r /content/usr/local/lib/python3.7/dist-packages/transformers\n",
        "    !rm -r /content/usr/local/lib/python3.7/dist-packages/transformers-4.19.2.dist-info\n",
        "    !rm -r /content/usr/local/lib/python3.7/dist-packages/diffusers\n",
        "    !rm -r /content/usr/local/lib/python3.7/dist-packages/diffusers-0.3.0.dist-info\n",
        "    !rm -r /content/usr/local/lib/python3.7/dist-packages/accelerate\n",
        "    !rm -r /content/usr/local/lib/python3.7/dist-packages/accelerate-0.12.0.dist-info    \n",
        "    !cp -r /content/usr/local/lib/python3.7/dist-packages /usr/local/lib/python3.7/\n",
        "    !rm -r /content/usr\n",
        "    !rm Dependencies_AUT.7z.001\n",
        "    !rm Dependencies_AUT.7z.002\n",
        "    %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/ldm/modules\n",
        "    !wget -O attention.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/precompiled/attention.py\n",
        "    \n",
        "\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/modules\n",
        "  !wget -O paths.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/AUTOMATIC1111_files/paths.py\n",
        "  if not os.path.exists('/tools/node/bin/lt'):\n",
        "    !npm install -g localtunnel\n",
        "\n",
        "with capture.capture_output() as cap: \n",
        "  %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/\n",
        "  time.sleep(1)\n",
        "  !wget -O webui.py https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.py\n",
        "  !sed -i 's@gpu_call).*@gpu_call) \\n        demo.queue(concurrency_count=111500)@' /content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.py\n",
        "  %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/\n",
        "  !wget -O ui.py https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/modules/ui.py\n",
        "  !sed -i 's@css = \"\".*@with open(os.path.join(script_path, \"style.css\"), \"r\", encoding=\"utf8\") as file:\\n        css = file.read()@' /content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/ui.py  \n",
        "  %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui\n",
        "  !wget -O style.css https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/style.css\n",
        "  !sed -i 's@min-height: 4.*@min-height: 5.5em;@g' /content/gdrive/MyDrive/sd/stable-diffusion-webui/style.css  \n",
        "  %cd /content\n",
        "\n",
        "\n",
        "Use_Gradio_Server = False #@param {type:\"boolean\"}\n",
        "#@markdown  - Only if you have trouble connecting to the local server\n",
        "\n",
        "\n",
        "share=''\n",
        "if Use_Gradio_Server:\n",
        "  share='--share'\n",
        "  !sed -i '1037s@.*@            self.server_name = server_name@' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py\n",
        "  !sed -i '1039s@.*@            self.server_port = server_port@' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py  \n",
        "  !sed -i '1043s@.*@            self.protocol = \"https\" if self.local_url.startswith(\"https\") else \"http\"@' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py  \n",
        "  clear_output()\n",
        "  \n",
        "else:\n",
        "  share=''\n",
        "\n",
        "  !nohup lt --port 7860 > srv.txt 2>&1 &\n",
        "  time.sleep(2)\n",
        "  !grep -o 'https[^ ]*' /content/srv.txt >srvr.txt\n",
        "  time.sleep(2)\n",
        "  srv= getoutput('cat /content/srvr.txt')\n",
        "\n",
        "  !sed -i '1037s@.*@            self.server_name = \"{srv[8:]}\"@' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py\n",
        "  !sed -i '1039s@.*@            self.server_port = 443@' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py\n",
        "  !sed -i '1043s@.*@            self.protocol = \"https\"@' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py  \n",
        "          \n",
        "  !sed -i '13s@.*@    \"PUBLIC_SHARE_TRUE\": \"\u001b[32mConnected\",@' /usr/local/lib/python3.7/dist-packages/gradio/strings.py\n",
        "  \n",
        "  !rm /content/srv.txt\n",
        "  !rm /content/srvr.txt\n",
        "  clear_output()\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content/gdrive/MyDrive/sd/stable-diffusion/\n",
        "\n",
        "!python /content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.py $share --disable-safe-unpickle --ckpt \"$path_to_trained_model\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "WCgtpGr6ZOyG",
        "CnBAZ4eje2Sl",
        "rYmyuQctfATh",
        "Qbclw_Gmg3DC"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
